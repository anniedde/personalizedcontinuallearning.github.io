<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Continual Learning of Personalized Generative Face Models with Experience Replay.">
  <meta name="keywords" content="Continual Learning, personalization, 3D">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Continual Learning of Personalized Generative Face Models with Experience Replay</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="icon" href="./static/images/favicon.png">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Continual Learning of Personalized Generative Face Models with Experience Replay</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/annie-w-928955101/">Annie Wang</a>,</span>
            <span class="author-block">
              <a href="https://luchaoqi.com/">Luchao Qi</a>,</span>
            <span class="author-block">
              <a href="https://www.cs.unc.edu/~ronisen/">Roni Sengupta</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of North Carolina at Chapel Hill</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a class="button is-normal is-rounded is-light">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark"  href="supplementary.html">
                 
                  <span>Supplemental Material</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser ">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" src="./static/images/teaser.png"> 
      </img>
      <h2 class="subtitle has-text-centered">
        We mitigate catastrophic forgetting in the continual personalization of generative 2D and 3D models.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce a novel continual learning problem: how to sequentially update the weights of a personalized 2D and 3D generative face model as new batches of photos in different appearances, styles, poses, and lighting are captured regularly. 
          </p>
          <p>
            We observe that naive sequential fine-tuning of the model leads to catastrophic forgetting of past representations of the individual's face. 
            We then demonstrate that a simple random sampling-based experience replay method is effective at mitigating catastrophic forgetting when a relatively large number of images can be stored and replayed. 
            However, for long-term deployment of these models with relatively smaller storage, this simple random sampling-based replay technique also forgets past representations. 
          </p>
          <p>
            Thus, we introduce a novel experience replay algorithm that combines random sampling with StyleGAN's latent space to represent the buffer as an optimal convex hull. 
            We observe that our proposed convex hull-based experience replay is more effective in preventing forgetting than a random sampling baseline and the lower bound. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">ER-Rand</h2>
          <p>
            We show that this simple experience replay method using random sampling, which we dub <i>ER-Rand</i>, works well with a large buffer size.
          </p>
          <img id="er-rand" src="./static/images/ER-Rand.png">
        </img>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">ER-Hull</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We also introduce a new experience replay sampling algorithm, <i>ER-Hull</i>, that chooses how to populate the buffer based on the volume of the convex hull of the samples' corresponding vectors in the StyleGAN latent space.
            </p>
            <img id="er-hull" src="./static/images/ER-Hull.png">
          </img>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Quantitative Results</h2>
        <div class="content has-text-justified">
          <p>
            We compare our methods to the upper bound of full finetuning across all timestamps, and the lower bound of naive sequential training on each timestamp without experience replay.
          </p>
        </div>
        
        <!-- Interpolating. -->
        <h3 class="title is-4">2D Quantitative Results</h3>
        <div class="content has-text-justified">
          <p>
            Continual Learning performance of personalized StyleGAN (MyStyle) in inverting an unseen test image <i>(left)</i> and synthesizing novel appearance <i>(right)</i>, evaluated with Average Incremental Performance (AIP) measured with LPIPS (lower is better) and ID similarity (higher is better) as well as Forgetting of both metrics (lower is better), scaled by x10. 
            ER-Rand and ER-Hull perform experience replay with simple random sampling and proposed convex hull optimization in StyleGAN latent space respectively.
          </p>
          <img id="2d-quantitative" src="./static/images/2d_quantitative.png">
        </div>

        <!-- Interpolating. -->
        <h3 class="title is-4">3D Quantitative Results</h3>
        <div class="content has-text-justified">
          <p>
            Continual Learning performance of personalized EG3D (My3DGen) in reconstructing an unseen test image, evaluated with Average Incremental Performance (AIP) and Forgetting metrics measured with LPIPS (lower is better) and ID similarity (higher is better), scaled by ×10. 
            ER-Rand and ER-Hull perform experience replay with simple random sampling and proposed convex hull optimization in StyleGAN latent space respectively. Buffer size is 3.
          </p>
          <img id="3d-quantitative-reconstruction" src="./static/images/3d_reconstruction_quantitative.png">
          <p></p>
          <p>
            Continual Learning performance of personalized EG3D (My3DGen) in synthesizing novel appearance, evaluated with Average Incremental Performance (AIP) and Forgetting metrics measured with LPIPS (lower is better) and ID similarity (higher is better), scaled by ×10. 
            ER-Rand and ER-Hull perform experience replay with simple random sampling and proposed convex hull optimization in StyleGAN latent space respectively. Buffer size is 3.
          </p>
          <img id="3d-quantitative-synthesis" src="./static/images/3d_synthesis_quantitative.png">
        </div>


        
        <br/>
        <!--/ Interpolating. -->
      </div>
    </div>

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Image Reconstruction</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">2D Reconstruction</h3>
        <div class="content has-text-justified">
          <p>
            Example comparison of our methods with buffer size of 3 vs upper bound (full finetuning) and lower bound (naive sequential training). <i>Celebrity shown: IU</i>
          </p>
        </div>
        <div class="content has-text-centered">
          <p>
            <img id="iu-2d-reconstruction" src="./static/images/2d_recon_fig.png" class="center" width="600">
          </p>
        </div>
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">3D Reconstruction</h3>
        <div class="content has-text-justified">
          <p>
            Example comparison of our methods with buffer size of 3 vs upper bound (full finetuning) and lower bound (naive sequential training). <i>Celebrity shown: Harry Styles</i>
          </p>
        </div>
        <div class="content has-text-centered">
          <p>
            <img id="harry-3d-reconstruction" src="./static/images/3d_recon_harry_fig.png" class="center" width="600">
          </p>
        </div>
      </div>
    </div>

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Image Synthesis</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">2D Synthesis</h3>
        <div class="content has-text-justified">
          <p>
            Example comparison of our methods with buffer size of 3 vs upper bound (full finetuning) and lower bound (naive sequential training). <i>Celebrity shown: Margot Robbie</i>
          </p>
          
        </div>
        <div class="content has-text-centered">
          <p>
            <img id="margot-2d-synthesis" src="./static/images/2d_synth_margot_fig.png" class="center" width="600">
          </p>
        </div>
        
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">3D Synthesis</h3>
        <div class="content has-text-justified">
          <p>
            Example comparison of our methods with buffer size of 3 vs upper bound (full finetuning) and lower bound (naive sequential training). <i>Celebrity shown: Michael B. Jordan</i>
          </p>
        </div>
        <div class="content has-text-centered">
          <p>
            <img id="michael-3d-synthesis" src="./static/images/3d_synth_michael_fig.png" class="center" width="600">
          </p>
        </div>
      </div>
    </div>

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>
        <div class="content has-text-justified">
          <p>
            Our generative model personalization is based on the <a href="https://my3dgen.github.io/">My3DGen</a> Framework.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website template credits to <a
              href="https://nerfies.github.io/">Nerfies</a>.
            
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
